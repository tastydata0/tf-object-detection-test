{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dataclasses\n",
    "\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.compat.v1.Session(config=config)\n",
    "\n",
    "from google.protobuf import text_format\n",
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "tf.test.is_gpu_available(), tf.test.gpu_device_name()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MODEL_URL = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz'\n",
    "MODEL_NAME = MODEL_URL.split('/')[-1].split('.')[0]\n",
    "MODEL_NAME\n",
    "CUSTOM_MODEL_NAME = 'my_ssd_net2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclasses.dataclass\n",
    "class Paths:\n",
    "    tensorflow_dir: str = os.path.join('Tensorflow')\n",
    "    models_dir: str = os.path.join(tensorflow_dir, 'models')\n",
    "    custom_model_dir: str = os.path.join(models_dir, CUSTOM_MODEL_NAME)\n",
    "    api_model_dir: str = os.path.join(tensorflow_dir, 'api_model')\n",
    "    annotations_dir: str = os.path.join(tensorflow_dir, 'annotations')\n",
    "    exported_models_dir: str = os.path.join(tensorflow_dir, 'exported_models')\n",
    "    images_dir: str = os.path.join(tensorflow_dir, 'images')\n",
    "    images_test_dir: str = os.path.join(images_dir, 'test')\n",
    "    images_train_dir: str = os.path.join(images_dir, 'train')\n",
    "    pre_trained_models_dir: str = os.path.join(tensorflow_dir, 'pre_trained_models')\n",
    "    scriprs_dir: str = os.path.join(tensorflow_dir, 'scripts')\n",
    "    records_dir: str = os.path.join(tensorflow_dir, 'records')\n",
    "    checkpoints_dir: str = os.path.join(tensorflow_dir, 'checkpoints')\n",
    "\n",
    "    \n",
    "paths = Paths()\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class Files:\n",
    "    record_file: str = os.path.join(paths.records_dir, 'people.record')\n",
    "    val_record_file: str = os.path.join(paths.records_dir, 'val_people.record')\n",
    "    tf_record_generator_file: str = os.path.join(paths.scriprs_dir, 'my_tf_record.py')\n",
    "    pipeline_config_file: str = os.path.join(paths.models_dir, CUSTOM_MODEL_NAME, 'pipeline.config')\n",
    "    label_map_file: str = os.path.join(paths.annotations_dir, 'label_map.pbtxt')\n",
    "    training_script_file: str = os.path.join(paths.api_model_dir,'research', 'object_detection', 'model_main_tf2.py')\n",
    "\n",
    "files = Files()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in dataclasses.asdict(paths).values():\n",
    "    if not os.path.exists(i):\n",
    "        os.mkdir(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join(paths.api_model_dir, 'research')):\n",
    "    !git clone https://github.com/tensorflow/models.git $paths.api_model_dir\n",
    "else:\n",
    "    print('Api model already exists')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import object_detection\n",
    "    print('Object detection is already installed')\n",
    "except ImportError:\n",
    "    # Install object detection api\n",
    "    !cd {paths.api_model_dir}/research && protoc object_detection/protos/*.proto --python_out=. && cp object_detection/packages/tf2/setup.py . && python -m pip install ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip list | grep object-detection\n",
    "!pip list | grep tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train record\n",
    "if not os.path.exists(files.record_file):\n",
    "    !python {files.tf_record_generator_file} -a '{paths.annotations_dir}/train_bboxes.txt' -i '{paths.images_dir}' -o '{files.record_file}'\n",
    "else:\n",
    "    print('Train record already exists')\n",
    "\n",
    "# Val record\n",
    "if not os.path.exists(files.val_record_file):\n",
    "    !python {files.tf_record_generator_file} -a '{paths.annotations_dir}/val_bboxes.txt' -i '{paths.images_dir}' -o '{files.val_record_file}'\n",
    "else:\n",
    "    print('Val record already exists')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join(paths.pre_trained_models_dir, MODEL_NAME)):\n",
    "    !wget {MODEL_URL} -O {paths.pre_trained_models_dir}/{MODEL_NAME}.tar.gz\n",
    "    !tar -xzvf {paths.pre_trained_models_dir}/{MODEL_NAME}.tar.gz -C {paths.pre_trained_models_dir}\n",
    "else: \n",
    "    print('Pre-trained model already exists')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp {paths.pre_trained_models_dir}/{MODEL_NAME}/pipeline.config {files.pipeline_config_file}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from object_detection.utils import config_util\n",
    "from object_detection.protos import pipeline_pb2\n",
    "config = config_util.get_configs_from_pipeline_file(files.pipeline_config_file)\n",
    "\n",
    "pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
    "with tf.io.gfile.GFile(files.pipeline_config_file, \"r\") as f:\n",
    "    proto_str = f.read()\n",
    "    text_format.Merge(proto_str, pipeline_config)\n",
    "\n",
    "pipeline_config.model.ssd.num_classes = 1\n",
    "pipeline_config.train_config.batch_size = 4\n",
    "pipeline_config.train_config.fine_tune_checkpoint = os.path.join(\n",
    "    paths.pre_trained_models_dir, MODEL_NAME, 'checkpoint', 'ckpt-0')\n",
    "pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n",
    "pipeline_config.train_input_reader.label_map_path = files.label_map_file\n",
    "pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [\n",
    "    os.path.join(paths.records_dir, 'people.record')]\n",
    "pipeline_config.eval_input_reader[0].label_map_path = files.label_map_file\n",
    "pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [\n",
    "    os.path.join(paths.records_dir, 'val.record')]\n",
    "\n",
    "\n",
    "config_text = text_format.MessageToString(pipeline_config)\n",
    "with tf.io.gfile.GFile(files.pipeline_config_file, \"wb\") as f:\n",
    "    f.write(config_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_COMMAND = f'python {files.training_script_file} --model_dir {os.path.join(paths.models_dir, CUSTOM_MODEL_NAME)} --pipeline_config_path {files.pipeline_config_file}'\n",
    "print(TRAINING_COMMAND)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{TRAINING_COMMAND}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd /home/alex/Desktop && tensorboard --logdir ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Load Train Model From Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.builders import model_builder\n",
    "from object_detection.utils import config_util\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pipeline config and build a detection model\n",
    "configs = config_util.get_configs_from_pipeline_file(\n",
    "    files.pipeline_config_file)\n",
    "detection_model = model_builder.build(\n",
    "    model_config=configs['model'], is_training=False)\n",
    "\n",
    "# Restore checkpoint\n",
    "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
    "ckpt.restore(os.path.join(paths.checkpoints_dir, 'ckpt-13')).expect_partial()\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def detect_fn(image):\n",
    "    image, shapes = detection_model.preprocess(image)\n",
    "    prediction_dict = detection_model.predict(image, shapes)\n",
    "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
    "    return detections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Real Time Detections from your Webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall -y opencv-python\n",
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall opencv-python-headless -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "print(cap.read())\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    image_np = np.array(frame)\n",
    "    input_tensor = tf.convert_to_tensor(\n",
    "        np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "    detections = detect_fn(input_tensor)\n",
    "\n",
    "    num_detections = int(detections.pop('num_detections'))\n",
    "    detections = {key: value[0, :num_detections].numpy()\n",
    "                  for key, value in detections.items()}\n",
    "    detections['num_detections'] = num_detections\n",
    "\n",
    "    # detection_classes should be ints.\n",
    "    detections['detection_classes'] = detections['detection_classes'].astype(\n",
    "        np.int64)\n",
    "\n",
    "    label_id_offset = 1\n",
    "    image_np_with_detections = image_np.copy()\n",
    "\n",
    "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "        image_np_with_detections,\n",
    "        detections['detection_boxes'],\n",
    "        detections['detection_classes']+label_id_offset,\n",
    "        detections['detection_scores'],\n",
    "        1,\n",
    "        use_normalized_coordinates=True,\n",
    "        max_boxes_to_draw=5,\n",
    "        min_score_thresh=.1,\n",
    "        agnostic_mode=False)\n",
    "\n",
    "    cv2.imshow('object detection',  cv2.resize(\n",
    "        image_np_with_detections, (800, 600)))\n",
    "\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "tfod",
   "language": "python",
   "name": "tfod"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
